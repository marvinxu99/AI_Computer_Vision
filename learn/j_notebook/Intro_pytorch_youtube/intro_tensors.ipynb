{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.pytorch.org/tutorials/beginner/introyt/tensors_deeper_tutorial.html\n",
    "\n",
    "Tensors are the central data abstraction in PyTorch. This interactive notebook provides an in-depth introduction to the torch.Tensor class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Creating Tensors\n",
    "# The simplest way to create a tensor is with the torch.empty() call:\n",
    "\n",
    "x = torch.empty(3, 4)\n",
    "print(type(x))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A brief note about tensors and their number of dimensions, and terminology:\n",
    "\n",
    "You will sometimes see a 1-dimensional tensor called a vector.\n",
    "\n",
    "Likewise, a 2-dimensional tensor is often referred to as a matrix.\n",
    "\n",
    "Anything with more than two dimensions is generally just called a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0.3126, 0.3791, 0.3087],\n",
      "        [0.0736, 0.4216, 0.0691]])\n"
     ]
    }
   ],
   "source": [
    "zeros = torch.zeros(2, 3)\n",
    "print(zeros)\n",
    "\n",
    "ones = torch.ones(2, 3)\n",
    "print(ones)\n",
    "\n",
    "torch.manual_seed(1729)\n",
    "random = torch.rand(2, 3)\n",
    "print(random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3126, 0.3791, 0.3087],\n",
      "        [0.0736, 0.4216, 0.0691]])\n",
      "tensor([[0.2332, 0.4047, 0.2162],\n",
      "        [0.9927, 0.4128, 0.5938]])\n",
      "tensor([[0.3126, 0.3791, 0.3087],\n",
      "        [0.0736, 0.4216, 0.0691]])\n",
      "tensor([[0.2332, 0.4047, 0.2162],\n",
      "        [0.9927, 0.4128, 0.5938]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1729)\n",
    "random1 = torch.rand(2, 3)\n",
    "print(random1)\n",
    "\n",
    "random2 = torch.rand(2, 3)\n",
    "print(random2)\n",
    "\n",
    "torch.manual_seed(1729)\n",
    "random3 = torch.rand(2, 3)\n",
    "print(random3)\n",
    "\n",
    "random4 = torch.rand(2, 3)\n",
    "print(random4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you should see above is that random1 and random3 carry identical values, as do random2 and random4. Manually setting the RNG’s seed resets it, so that identical computations depending on random number should, in most settings, provide identical results\n",
    "\n",
    "Tensor Shapes\n",
    "Often, when you’re performing operations on two or more tensors, they will need to be of the same shape - that is, having the same number of dimensions and the same number of cells in each dimension. For that, we have the torch.*_like() methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3])\n",
      "tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.]]])\n",
      "torch.Size([2, 2, 3])\n",
      "tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.]]])\n",
      "torch.Size([2, 2, 3])\n",
      "tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.]]])\n",
      "torch.Size([2, 2, 3])\n",
      "tensor([[[1., 1., 1.],\n",
      "         [1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.],\n",
      "         [1., 1., 1.]]])\n",
      "torch.Size([2, 2, 3])\n",
      "tensor([[[0.5062, 0.8469, 0.2588],\n",
      "         [0.2707, 0.4115, 0.6839]],\n",
      "\n",
      "        [[0.0703, 0.5105, 0.9451],\n",
      "         [0.2359, 0.1979, 0.3327]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(2, 2, 3)\n",
    "print(x.shape)\n",
    "print(x)\n",
    "\n",
    "empty_like_x = torch.empty_like(x)\n",
    "print(empty_like_x.shape)\n",
    "print(empty_like_x)\n",
    "\n",
    "zeros_like_x = torch.zeros_like(x)\n",
    "print(zeros_like_x.shape)\n",
    "print(zeros_like_x)\n",
    "\n",
    "ones_like_x = torch.ones_like(x)\n",
    "print(ones_like_x.shape)\n",
    "print(ones_like_x)\n",
    "\n",
    "rand_like_x = torch.rand_like(x)\n",
    "print(rand_like_x.shape)\n",
    "print(rand_like_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.1416, 2.7183],\n",
      "        [1.6180, 0.0073]])\n",
      "tensor([ 2,  3,  5,  7, 11, 13, 17, 19])\n",
      "tensor([[2, 4, 6],\n",
      "        [3, 6, 9]])\n"
     ]
    }
   ],
   "source": [
    "# The last way to create a tensor that will cover is to specify its data directly from a PyTorch collection:\n",
    "\n",
    "some_constants = torch.tensor([[3.1415926, 2.71828], [1.61803, 0.0072897]])\n",
    "print(some_constants)\n",
    "\n",
    "some_integers = torch.tensor((2, 3, 5, 7, 11, 13, 17, 19))\n",
    "print(some_integers)\n",
    "\n",
    "more_integers = torch.tensor(((2, 4, 6), [3, 6, 9]))\n",
    "print(more_integers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor Data Types\n",
    "Setting the datatype of a tensor is possible a couple of ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1]], dtype=torch.int16)\n",
      "tensor([[18.3283,  0.2118, 18.4972],\n",
      "        [ 9.8370,  3.8937, 16.1945]], dtype=torch.float64)\n",
      "tensor([[18,  0, 18],\n",
      "        [ 9,  3, 16]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones((2, 3), dtype=torch.int16)   # The simplest way to set the underlying data type of a tensor is with an optional argument at creation time\n",
    "print(a)\n",
    "\n",
    "b = torch.rand((2, 3), dtype=torch.float64) * 20.\n",
    "print(b)\n",
    "\n",
    "c = b.to(torch.int32)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Math & Logic with PyTorch Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[2., 2.],\n",
      "        [2., 2.]])\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]])\n",
      "tensor([[4., 4.],\n",
      "        [4., 4.]])\n",
      "tensor([[1.4142, 1.4142],\n",
      "        [1.4142, 1.4142]])\n"
     ]
    }
   ],
   "source": [
    "ones = torch.zeros(2, 2) + 1\n",
    "twos = torch.ones(2, 2) * 2\n",
    "threes = (torch.ones(2, 2) * 7 - 1) / 2\n",
    "fours = twos ** 2\n",
    "sqrt2s = twos ** 0.5\n",
    "\n",
    "print(ones)\n",
    "print(twos)\n",
    "print(threes)\n",
    "print(fours)\n",
    "print(sqrt2s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.,  4.],\n",
      "        [ 8., 16.]])\n",
      "tensor([[5., 5.],\n",
      "        [5., 5.]])\n",
      "tensor([[12., 12.],\n",
      "        [12., 12.]])\n"
     ]
    }
   ],
   "source": [
    "powers2 = twos ** torch.tensor([[1, 2], [3, 4]])\n",
    "print(powers2)\n",
    "\n",
    "fives = ones + fours\n",
    "print(fives)\n",
    "\n",
    "dozens = threes * fours\n",
    "print(dozens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Brief: Tensor Broadcasting\n",
    "\n",
    "Broadcasting is a way to perform an operation between tensors that have similarities in their shapes. In the example below, the one-row, four-column tensor is multiplied by both rows of the two-row, four-column tensor.\n",
    "\n",
    "This is an important operation in Deep Learning. The common example is multiplying a tensor of learning weights by a batch of input tensors, applying the operation to each instance in the batch separately, and returning a tensor of identical shape - just like our (2, 4) * (1, 4) example below returned a tensor of shape (2, 4).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2024, 0.5731, 0.7191, 0.4067],\n",
      "        [0.7301, 0.6276, 0.7357, 0.0381]])\n",
      "tensor([[0.4049, 1.1461, 1.4382, 0.8134],\n",
      "        [1.4602, 1.2551, 1.4715, 0.0762]])\n"
     ]
    }
   ],
   "source": [
    "rand = torch.rand(2, 4)\n",
    "doubled = rand * (torch.ones(1, 4) * 2)\n",
    "\n",
    "print(rand)\n",
    "print(doubled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rules for broadcasting are:\n",
    "\n",
    "- Each tensor must have at least one dimension - no empty tensors.\n",
    "- Comparing the dimension sizes of the two tensors, going from last to first:\n",
    "    - Each dimension must be equal, or\n",
    "    - One of the dimensions must be of size 1, or\n",
    "    - The dimension does not exist in one of the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2138, 0.5395],\n",
      "         [0.3686, 0.4007],\n",
      "         [0.7220, 0.8217]],\n",
      "\n",
      "        [[0.2138, 0.5395],\n",
      "         [0.3686, 0.4007],\n",
      "         [0.7220, 0.8217]],\n",
      "\n",
      "        [[0.2138, 0.5395],\n",
      "         [0.3686, 0.4007],\n",
      "         [0.7220, 0.8217]],\n",
      "\n",
      "        [[0.2138, 0.5395],\n",
      "         [0.3686, 0.4007],\n",
      "         [0.7220, 0.8217]]])\n",
      "tensor([[[0.2612, 0.2612],\n",
      "         [0.7375, 0.7375],\n",
      "         [0.8328, 0.8328]],\n",
      "\n",
      "        [[0.2612, 0.2612],\n",
      "         [0.7375, 0.7375],\n",
      "         [0.8328, 0.8328]],\n",
      "\n",
      "        [[0.2612, 0.2612],\n",
      "         [0.7375, 0.7375],\n",
      "         [0.8328, 0.8328]],\n",
      "\n",
      "        [[0.2612, 0.2612],\n",
      "         [0.7375, 0.7375],\n",
      "         [0.8328, 0.8328]]])\n",
      "tensor([[[0.8444, 0.2941],\n",
      "         [0.8444, 0.2941],\n",
      "         [0.8444, 0.2941]],\n",
      "\n",
      "        [[0.8444, 0.2941],\n",
      "         [0.8444, 0.2941],\n",
      "         [0.8444, 0.2941]],\n",
      "\n",
      "        [[0.8444, 0.2941],\n",
      "         [0.8444, 0.2941],\n",
      "         [0.8444, 0.2941]],\n",
      "\n",
      "        [[0.8444, 0.2941],\n",
      "         [0.8444, 0.2941],\n",
      "         [0.8444, 0.2941]]])\n"
     ]
    }
   ],
   "source": [
    "a =     torch.ones(4, 3, 2)\n",
    "\n",
    "b = a * torch.rand(   3, 2) # 3rd & 2nd dims identical to a, dim 1 absent\n",
    "print(b)\n",
    "\n",
    "c = a * torch.rand(   3, 1) # 3rd dim = 1, 2nd dim identical to a\n",
    "print(c)\n",
    "\n",
    "d = a * torch.rand(   1, 2) # 3rd dim identical to a, 2nd dim = 1\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look closely at the values of each tensor above:\n",
    "\n",
    "- The multiplication operation that created b was broadcast over every “layer” of a.\n",
    "- For c, the operation was broadcast over every layer and row of a - every 3-element column is identical.\n",
    "- For d, we switched it around - now every row is identical, across layers and columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More Math with Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2285,  0.9767, -0.0476,  0.4484],\n",
      "        [-0.8447, -0.1992,  0.9755, -0.9295]])\n",
      "Common functions:\n",
      "tensor([[0.2285, 0.9767, 0.0476, 0.4484],\n",
      "        [0.8447, 0.1992, 0.9755, 0.9295]])\n",
      "tensor([[-0., 1., -0., 1.],\n",
      "        [-0., -0., 1., -0.]])\n",
      "tensor([[-1.,  0., -1.,  0.],\n",
      "        [-1., -1.,  0., -1.]])\n",
      "tensor([[-0.2285,  0.5000, -0.0476,  0.4484],\n",
      "        [-0.5000, -0.1992,  0.5000, -0.5000]])\n"
     ]
    }
   ],
   "source": [
    "# common functions\n",
    "a = torch.rand(2, 4) * 2 - 1\n",
    "print(a)\n",
    "print('Common functions:')\n",
    "print(torch.abs(a))\n",
    "print(torch.ceil(a))\n",
    "print(torch.floor(a))\n",
    "print(torch.clamp(a, -0.5, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sine and arcsine:\n",
      "tensor([0.0000, 0.7854, 1.5708, 2.3562])\n",
      "tensor([0.0000, 0.7071, 1.0000, 0.7071])\n",
      "tensor([0.0000, 0.7854, 1.5708, 0.7854])\n"
     ]
    }
   ],
   "source": [
    "# trigonometric functions and their inverses\n",
    "angles = torch.tensor([0, math.pi / 4, math.pi / 2, 3 * math.pi / 4])\n",
    "sines = torch.sin(angles)\n",
    "inverses = torch.asin(sines)\n",
    "print('\\nSine and arcsine:')\n",
    "print(angles)\n",
    "print(sines)\n",
    "print(inverses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bitwise XOR:\n",
      "tensor([3, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "# bitwise operations\n",
    "print('\\nBitwise XOR:')\n",
    "b = torch.tensor([1, 5, 11])\n",
    "c = torch.tensor([2, 7, 10])\n",
    "print(torch.bitwise_xor(b, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Broadcasted, element-wise equality comparison:\n",
      "tensor([[ True, False],\n",
      "        [False, False]])\n"
     ]
    }
   ],
   "source": [
    "# comparisons:\n",
    "print('\\nBroadcasted, element-wise equality comparison:')\n",
    "d = torch.tensor([[1., 2.], [3., 4.]])\n",
    "e = torch.ones(1, 2)  # many comparison ops support broadcasting!\n",
    "print(torch.eq(d, e)) # returns a tensor of type bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "\n",
      "Reduction ops:\n",
      "tensor(4.)\n",
      "4.0\n",
      "tensor(2.5000)\n",
      "tensor(1.2910)\n",
      "tensor(24.)\n",
      "tensor([1, 2])\n"
     ]
    }
   ],
   "source": [
    "# reductions:\n",
    "print(d)\n",
    "print('\\nReduction ops:')\n",
    "print(torch.max(d))        # returns a single-element tensor\n",
    "print(torch.max(d).item()) # extracts the value from the returned tensor\n",
    "print(torch.mean(d))       # average\n",
    "print(torch.std(d))        # standard deviation\n",
    "print(torch.prod(d))       # product of all numbers\n",
    "print(torch.unique(torch.tensor([1, 2, 1, 2, 1, 2]))) # filter unique elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vectors & Matrices:\n",
      "tensor([ 0.,  0., -1.])\n",
      "tensor([[0.0905, 0.4485],\n",
      "        [0.8740, 0.2526]])\n",
      "tensor([[0.2715, 1.3456],\n",
      "        [2.6220, 0.7577]])\n",
      "torch.return_types.linalg_svd(\n",
      "U=tensor([[-0.2748, -0.9615],\n",
      "        [-0.9615,  0.2748]]),\n",
      "S=tensor([2.8184, 1.1788]),\n",
      "Vh=tensor([[-0.9210, -0.3897],\n",
      "        [ 0.3897, -0.9210]]))\n"
     ]
    }
   ],
   "source": [
    "# vector and linear algebra operations\n",
    "v1 = torch.tensor([1., 0., 0.])         # x unit vector\n",
    "v2 = torch.tensor([0., 1., 0.])         # y unit vector\n",
    "m1 = torch.rand(2, 2)                   # random matrix\n",
    "m2 = torch.tensor([[3., 0.], [0., 3.]]) # three times identity matrix\n",
    "\n",
    "print('\\nVectors & Matrices:')\n",
    "print(torch.linalg.cross(v2, v1)) # negative of z unit vector (v1 x v2 == -v2 x v1)\n",
    "print(m1)\n",
    "m3 = torch.linalg.matmul(m1, m2)\n",
    "print(m3)                  # 3 times m1\n",
    "print(torch.linalg.svd(m3))       # singular value decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Altering Tensors in Place\n",
    "Most binary operations on tensors will return a third, new tensor. When we say c = a * b (where a and b are tensors), the new tensor c will occupy a region of memory distinct from the other tensors.\n",
    "\n",
    "There are times, though, that you may wish to alter a tensor in place - for example, if you’re doing an element-wise computation where you can discard intermediate values. For this, most of the math functions have a version with an appended underscore (_) that will alter a tensor in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      "tensor([0.0000, 0.7854, 1.5708, 2.3562])\n",
      "tensor([0.0000, 0.7071, 1.0000, 0.7071])\n",
      "tensor([0.0000, 0.7854, 1.5708, 2.3562])\n",
      "\n",
      "b:\n",
      "tensor([0.0000, 0.7854, 1.5708, 2.3562])\n",
      "tensor([0.0000, 0.7071, 1.0000, 0.7071])\n",
      "tensor([0.0000, 0.7071, 1.0000, 0.7071])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([0, math.pi / 4, math.pi / 2, 3 * math.pi / 4])\n",
    "print('a:')\n",
    "print(a)\n",
    "print(torch.sin(a))   # this operation creates a new tensor in memory\n",
    "print(a)              # a has not changed\n",
    "\n",
    "b = torch.tensor([0, math.pi / 4, math.pi / 2, 3 * math.pi / 4])\n",
    "print('\\nb:')\n",
    "print(b)\n",
    "print(torch.sin_(b))  # note the underscore\n",
    "print(b)              # b has changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[0.6923, 0.7545],\n",
      "        [0.7746, 0.2330]])\n",
      "\n",
      "After adding:\n",
      "tensor([[1.6923, 1.7545],\n",
      "        [1.7746, 1.2330]])\n",
      "tensor([[1.6923, 1.7545],\n",
      "        [1.7746, 1.2330]])\n",
      "tensor([[0.6923, 0.7545],\n",
      "        [0.7746, 0.2330]])\n",
      "\n",
      "After multiplying\n",
      "tensor([[0.4793, 0.5693],\n",
      "        [0.5999, 0.0543]])\n",
      "tensor([[0.4793, 0.5693],\n",
      "        [0.5999, 0.0543]])\n"
     ]
    }
   ],
   "source": [
    "# In-place alerting for arithmetic operations\n",
    "a = torch.ones(2, 2)\n",
    "b = torch.rand(2, 2)\n",
    "\n",
    "print('Before:')\n",
    "print(a)\n",
    "print(b)\n",
    "print('\\nAfter adding:')\n",
    "print(a.add_(b))\n",
    "print(a)\n",
    "print(b)\n",
    "print('\\nAfter multiplying')\n",
    "print(b.mul_(b))\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is another option for placing the result of a computation in an existing, allocated tensor. \n",
    "Many of the methods and functions we’ve seen so far - including creation methods! - have an out argument that lets you specify a tensor to receive the output. \n",
    "If the out tensor is the correct shape and dtype, this can happen without a new memory allocation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.2655, 0.8926],\n",
      "        [0.7058, 0.6247]])\n",
      "tensor([[0.6545, 0.4144],\n",
      "        [0.0696, 0.4648]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(2, 2)\n",
    "b = torch.rand(2, 2)\n",
    "c = torch.zeros(2, 2)\n",
    "old_id = id(c)\n",
    "\n",
    "print(c)\n",
    "d = torch.matmul(a, b, out=c)\n",
    "print(c)                # contents of c have changed\n",
    "\n",
    "assert c is d           # test c & d are same object, not just containing equal values\n",
    "assert id(c) == old_id  # make sure that our new c is the same object as the old one\n",
    "\n",
    "torch.rand(2, 2, out=c) # works for creation too!\n",
    "print(c)                # c has changed again\n",
    "assert id(c) == old_id  # still the same object!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copying Tensors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
