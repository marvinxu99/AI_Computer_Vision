{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Understanding with Captum\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Captum’s approach to model interpretability is in terms of attributions. There are three kinds of attributions available in Captum:\n",
    "\n",
    "- Feature Attribution - seeks to explain a particular output in terms of features of the input that generated it. Explaining whether a movie review was positive or negative in terms of certain words in the review is an example of feature attribution.  \n",
    "    \n",
    "    “Which features of the input were most important for this prediction?”\n",
    "        - In NLP: Which words made a sentence classified as positive or negative?\n",
    "        - In vision: Which pixels most influenced the model to recognize a cat?\n",
    "\n",
    "- Layer Attribution - examines the activity of a model’s hidden layer subsequent to a particular input. Examining the spatially-mapped output of a convolutional layer in response to an input image in an example of layer attribution. \n",
    "    - Goal: Explain what happens inside the network, at the layer level.\n",
    "    - Question: “Which features or regions in this layer respond most to a given input?”\n",
    "\n",
    "    Example user cases:\n",
    "        - Visualizing activations of a CNN layer for an image\n",
    "        - Understanding how attention layers behave in a transformer\n",
    "\n",
    "- Neuron Attribution - is analagous to layer attribution, but focuses on the activity of a single neuron.\n",
    "    - Goal: Go even deeper — analyze the contribution to a single neuron.\n",
    "    - Question: “How important is this input for activating neuron X in layer Y?”\n",
    "\n",
    "    Use cases:\n",
    "    - Understanding what specific neurons detect (edges, textures, or semantic features) \n",
    "    - Debugging neuron saturation or dead neurons\n",
    "\n",
    "In this interactive notebook, we’ll look at Feature Attribution and Layer Attribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the three attribution types has multiple attribution algorithms associated with it. Many attribution algorithms fall into two broad categories:\n",
    "\n",
    "- Gradient-based algorithms - calculate the backward gradients of a model output, layer output, or neuron activation with respect to the input. Integrated Gradients (for features), Layer Gradient * Activation, and Neuron Conductance are all gradient-based algorithms.\n",
    "\n",
    "- Perturbation-based algorithms - examine the changes in the output of a model, layer, or neuron in response to changes in the input. The input perturbations may be directed or random. Occlusion, Feature Ablation, and Feature Permutation are all perturbation-based algorithms.\n",
    "\n",
    "We’ll be examining algorithms of both types below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:  pip install captum Flask-Compress - it uninstalled numpy 2.3.2 an replaced it with 1.26.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A First Example\n",
    "To start, let’s take a simple, visual example. We’ll start with a ResNet model pretrained on the ImageNet dataset. We’ll get a test input, and use different Feature Attribution algorithms to examine how the input images affect the output, and see a helpful visualization of this input attribution map for some test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "import captum\n",
    "from captum.attr import IntegratedGradients, Occlusion, LayerGradCam, LayerAttribution\n",
    "from captum.attr import visualization as viz\n",
    "\n",
    "import os, sys\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we’ll use the TorchVision model library to download a pretrained ResNet. Since we’re not training, we’ll place it in evaluation mode for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\marvi/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44.7M/44.7M [00:01<00:00, 43.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(weights='IMAGENET1K_V1')\n",
    "model = model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
